{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adc257/AmEx-Project/blob/Ye_branch/LSTM_implementation_3_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51KnKFxpvNB"
      },
      "source": [
        "# LSTM Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "X4FctTwRpvNE"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from transformers import TextClassificationPipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, AdamW, Trainer, TrainingArguments\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2EBev73pxMl",
        "outputId": "8fc49c03-46a2-4105-c0bd-5875716e0048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IQd64_TpvNF"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "RD-87QrlpvNF"
      },
      "outputs": [],
      "source": [
        "# Import train and test data\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Separate train labels and text\n",
        "train_labels = train['category']\n",
        "train_text = train['text']\n",
        "train_labels_list = train_labels.tolist()\n",
        "\n",
        "# Separate test labels and text\n",
        "test_labels = test['category']\n",
        "test_text = test['text']\n",
        "test_labels_list = test_labels.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziQYFurQpvNG"
      },
      "source": [
        "### Set 70% of the train dataset to be the train set, stratifying by the train labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "-g31uQYqpvNG"
      },
      "outputs": [],
      "source": [
        "# Create a stratified 70% sample of the train data\n",
        "train_text, test_text, train_labels, test_labels = train_test_split(train_text, train_labels, test_size=0.30, stratify=train_labels, random_state=42)\n",
        "\n",
        "# Reset the indices of the train_labels and test_labels Series as well as the train_text and test_text\n",
        "train_labels = train_labels.reset_index(drop=True)\n",
        "test_labels = test_labels.reset_index(drop=True)\n",
        "train_text = train_text.reset_index(drop=True)\n",
        "test_text = test_text.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwOiM01MwQII",
        "outputId": "d8c36f62-fb62-456a-b252-c6f8662b012f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "card_payment_fee_charged                            56\n",
              "direct_debit_payment_not_recognised                 55\n",
              "wrong_amount_of_cash_received                       54\n",
              "balance_not_updated_after_cheque_or_cash_deposit    54\n",
              "cash_withdrawal_charge                              53\n",
              "                                                    ..\n",
              "lost_or_stolen_card                                 25\n",
              "card_acceptance                                     18\n",
              "card_swallowed                                      18\n",
              "virtual_card_not_working                            12\n",
              "contactless_not_working                             10\n",
              "Name: category, Length: 77, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "test_labels.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T984bW9ZpvNG"
      },
      "source": [
        "### Shuffle 3% of Labels in Dn to Create Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Xn7LJENJHQNr"
      },
      "outputs": [],
      "source": [
        "def add_noise(labels, noise_level=0.03, seed=42):\n",
        "    # Set the seed for the random number generator\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Get unique labels and their counts\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "\n",
        "    # Calculate the number of labels to change for each unique label\n",
        "    n_noise_per_label = (noise_level * counts).astype(int)\n",
        "\n",
        "    # Create a copy of labels to work with\n",
        "    noisy_labels = labels.copy()\n",
        "\n",
        "    # Initialize an empty list to store noise indices\n",
        "    noise_indices = []\n",
        "\n",
        "    for lbl, n_noise in zip(unique_labels, n_noise_per_label):\n",
        "      if n_noise == 0:\n",
        "        n_noise = 1\n",
        "\n",
        "      # Get indices of current label\n",
        "      label_indices = np.where(labels == lbl)[0]\n",
        "\n",
        "      # Randomly select labels of current label to change\n",
        "      noise_indices_lbl = np.random.choice(label_indices, size=n_noise, replace=False)\n",
        "\n",
        "      # Add the noise indices for this label to the main list\n",
        "      noise_indices.extend(noise_indices_lbl)\n",
        "\n",
        "      # Get a list of labels excluding the current one\n",
        "      other_labels = [other_lbl for other_lbl in unique_labels if other_lbl != lbl]\n",
        "\n",
        "      for idx in noise_indices_lbl:\n",
        "          # Randomly select a new label\n",
        "          new_label = np.random.choice(other_labels)\n",
        "\n",
        "          # Replace the label at the current index with the new label\n",
        "          noisy_labels[idx] = new_label\n",
        "\n",
        "    return noisy_labels, np.array(noise_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ZpKi9KHVCwNM"
      },
      "outputs": [],
      "source": [
        "# Add noise to train and test labels and get the indices of the noised labels\n",
        "full_noised_train_labels, train_noise_indices = add_noise(train_labels)\n",
        "full_noised_test_labels, test_noise_indices = add_noise(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-0xgP6NwUVf",
        "outputId": "c0692bda-b13e-4c43-d0a6-55b1da335561"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "wrong_amount_of_cash_received                       56\n",
              "direct_debit_payment_not_recognised                 56\n",
              "card_payment_fee_charged                            56\n",
              "balance_not_updated_after_cheque_or_cash_deposit    55\n",
              "transaction_charged_twice                           54\n",
              "                                                    ..\n",
              "compromised_card                                    25\n",
              "card_acceptance                                     19\n",
              "card_swallowed                                      19\n",
              "virtual_card_not_working                            11\n",
              "contactless_not_working                             10\n",
              "Name: category, Length: 77, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "full_noised_test_labels.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dgTmtJpkpvNH",
        "outputId": "40cee8a6-6a12-487f-8faf-f2dcb334693c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text  \\\n",
              "0   What do I do if I detect fraudulent use on my ...   \n",
              "1   Ive been trying to use my card for two weeks n...   \n",
              "2   Why did the person I transferred money to not ...   \n",
              "3                     Is there a maximum for top-ups?   \n",
              "4   I desperately need to top-up my card, so why i...   \n",
              "5                          Can I order a card please?   \n",
              "6   The machine only paid me a hundred when I want...   \n",
              "7   How do I add the card I just received to show ...   \n",
              "8   How long does it take for money to transfer?  ...   \n",
              "9   I tried to make a transfer but it failed. will...   \n",
              "10           My new card came in.  How do I activate?   \n",
              "11             I believe my card payment has reverted   \n",
              "12          I couldnt transfer money from my account.   \n",
              "13    Are cards available to those outside of the UK?   \n",
              "14  I tried to get funds in hard cash but it was r...   \n",
              "15        Is there a way I can get my card expedited?   \n",
              "16    Why didn't my transfer to a beneficiary happen?   \n",
              "17  I transferred some money but it hasn't arrived...   \n",
              "18                  Why did I get a fee from the ATM?   \n",
              "19   Your machine took my card. How do I get it back?   \n",
              "20            Why have I been charged an extra pound?   \n",
              "21  I would like to get both Mastercard and Visa c...   \n",
              "22  I received my American Express in Apple Pay, i...   \n",
              "23              What happens when I am charged twice?   \n",
              "24  Can I use American express with apple pay? Why...   \n",
              "\n",
              "                                   category  k  \\\n",
              "0                          compromised_card  0   \n",
              "1                    reverted_card_payment?  0   \n",
              "2                      transfer_fee_charged  0   \n",
              "3                             top_up_limits  0   \n",
              "4                             top_up_failed  0   \n",
              "5                       order_physical_card  0   \n",
              "6             wrong_amount_of_cash_received  0   \n",
              "7                              card_linking  0   \n",
              "8        transfer_not_received_by_recipient  0   \n",
              "9                           failed_transfer  0   \n",
              "10                         activate_my_card  0   \n",
              "11                   reverted_card_payment?  0   \n",
              "12                          failed_transfer  0   \n",
              "13                          country_support  0   \n",
              "14                 declined_cash_withdrawal  0   \n",
              "15                             card_arrival  0   \n",
              "16                  beneficiary_not_allowed  0   \n",
              "17  balance_not_updated_after_bank_transfer  0   \n",
              "18                   cash_withdrawal_charge  0   \n",
              "19                           card_swallowed  0   \n",
              "20                extra_charge_on_statement  0   \n",
              "21                       visa_or_mastercard  0   \n",
              "22                  apple_pay_or_google_pay  0   \n",
              "23                transaction_charged_twice  0   \n",
              "24                  apple_pay_or_google_pay  0   \n",
              "\n",
              "                                          l  \\\n",
              "0                          compromised_card   \n",
              "1                    reverted_card_payment?   \n",
              "2                      transfer_fee_charged   \n",
              "3                             top_up_limits   \n",
              "4                             top_up_failed   \n",
              "5                       order_physical_card   \n",
              "6             wrong_amount_of_cash_received   \n",
              "7                              card_linking   \n",
              "8        transfer_not_received_by_recipient   \n",
              "9                           failed_transfer   \n",
              "10                         activate_my_card   \n",
              "11                   reverted_card_payment?   \n",
              "12                          failed_transfer   \n",
              "13                          country_support   \n",
              "14                 declined_cash_withdrawal   \n",
              "15                             card_arrival   \n",
              "16                  beneficiary_not_allowed   \n",
              "17  balance_not_updated_after_bank_transfer   \n",
              "18                   cash_withdrawal_charge   \n",
              "19                           card_swallowed   \n",
              "20                extra_charge_on_statement   \n",
              "21                       visa_or_mastercard   \n",
              "22                  apple_pay_or_google_pay   \n",
              "23                transaction_charged_twice   \n",
              "24                  apple_pay_or_google_pay   \n",
              "\n",
              "                                    l_prime  \n",
              "0                          compromised_card  \n",
              "1                    reverted_card_payment?  \n",
              "2                      transfer_fee_charged  \n",
              "3                             top_up_limits  \n",
              "4                             top_up_failed  \n",
              "5                       order_physical_card  \n",
              "6             wrong_amount_of_cash_received  \n",
              "7                              card_linking  \n",
              "8        transfer_not_received_by_recipient  \n",
              "9                           failed_transfer  \n",
              "10                         activate_my_card  \n",
              "11                   reverted_card_payment?  \n",
              "12                          failed_transfer  \n",
              "13                          country_support  \n",
              "14                 declined_cash_withdrawal  \n",
              "15                             card_arrival  \n",
              "16                  beneficiary_not_allowed  \n",
              "17  balance_not_updated_after_bank_transfer  \n",
              "18                   cash_withdrawal_charge  \n",
              "19                           card_swallowed  \n",
              "20                extra_charge_on_statement  \n",
              "21                       visa_or_mastercard  \n",
              "22                  apple_pay_or_google_pay  \n",
              "23                transaction_charged_twice  \n",
              "24                  apple_pay_or_google_pay  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9b8f62a-a0ac-42b4-945b-74373210fdd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>k</th>\n",
              "      <th>l</th>\n",
              "      <th>l_prime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What do I do if I detect fraudulent use on my ...</td>\n",
              "      <td>compromised_card</td>\n",
              "      <td>0</td>\n",
              "      <td>compromised_card</td>\n",
              "      <td>compromised_card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ive been trying to use my card for two weeks n...</td>\n",
              "      <td>reverted_card_payment?</td>\n",
              "      <td>0</td>\n",
              "      <td>reverted_card_payment?</td>\n",
              "      <td>reverted_card_payment?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why did the person I transferred money to not ...</td>\n",
              "      <td>transfer_fee_charged</td>\n",
              "      <td>0</td>\n",
              "      <td>transfer_fee_charged</td>\n",
              "      <td>transfer_fee_charged</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is there a maximum for top-ups?</td>\n",
              "      <td>top_up_limits</td>\n",
              "      <td>0</td>\n",
              "      <td>top_up_limits</td>\n",
              "      <td>top_up_limits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I desperately need to top-up my card, so why i...</td>\n",
              "      <td>top_up_failed</td>\n",
              "      <td>0</td>\n",
              "      <td>top_up_failed</td>\n",
              "      <td>top_up_failed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Can I order a card please?</td>\n",
              "      <td>order_physical_card</td>\n",
              "      <td>0</td>\n",
              "      <td>order_physical_card</td>\n",
              "      <td>order_physical_card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The machine only paid me a hundred when I want...</td>\n",
              "      <td>wrong_amount_of_cash_received</td>\n",
              "      <td>0</td>\n",
              "      <td>wrong_amount_of_cash_received</td>\n",
              "      <td>wrong_amount_of_cash_received</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How do I add the card I just received to show ...</td>\n",
              "      <td>card_linking</td>\n",
              "      <td>0</td>\n",
              "      <td>card_linking</td>\n",
              "      <td>card_linking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How long does it take for money to transfer?  ...</td>\n",
              "      <td>transfer_not_received_by_recipient</td>\n",
              "      <td>0</td>\n",
              "      <td>transfer_not_received_by_recipient</td>\n",
              "      <td>transfer_not_received_by_recipient</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I tried to make a transfer but it failed. will...</td>\n",
              "      <td>failed_transfer</td>\n",
              "      <td>0</td>\n",
              "      <td>failed_transfer</td>\n",
              "      <td>failed_transfer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>My new card came in.  How do I activate?</td>\n",
              "      <td>activate_my_card</td>\n",
              "      <td>0</td>\n",
              "      <td>activate_my_card</td>\n",
              "      <td>activate_my_card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I believe my card payment has reverted</td>\n",
              "      <td>reverted_card_payment?</td>\n",
              "      <td>0</td>\n",
              "      <td>reverted_card_payment?</td>\n",
              "      <td>reverted_card_payment?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I couldnt transfer money from my account.</td>\n",
              "      <td>failed_transfer</td>\n",
              "      <td>0</td>\n",
              "      <td>failed_transfer</td>\n",
              "      <td>failed_transfer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Are cards available to those outside of the UK?</td>\n",
              "      <td>country_support</td>\n",
              "      <td>0</td>\n",
              "      <td>country_support</td>\n",
              "      <td>country_support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I tried to get funds in hard cash but it was r...</td>\n",
              "      <td>declined_cash_withdrawal</td>\n",
              "      <td>0</td>\n",
              "      <td>declined_cash_withdrawal</td>\n",
              "      <td>declined_cash_withdrawal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Is there a way I can get my card expedited?</td>\n",
              "      <td>card_arrival</td>\n",
              "      <td>0</td>\n",
              "      <td>card_arrival</td>\n",
              "      <td>card_arrival</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Why didn't my transfer to a beneficiary happen?</td>\n",
              "      <td>beneficiary_not_allowed</td>\n",
              "      <td>0</td>\n",
              "      <td>beneficiary_not_allowed</td>\n",
              "      <td>beneficiary_not_allowed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>I transferred some money but it hasn't arrived...</td>\n",
              "      <td>balance_not_updated_after_bank_transfer</td>\n",
              "      <td>0</td>\n",
              "      <td>balance_not_updated_after_bank_transfer</td>\n",
              "      <td>balance_not_updated_after_bank_transfer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Why did I get a fee from the ATM?</td>\n",
              "      <td>cash_withdrawal_charge</td>\n",
              "      <td>0</td>\n",
              "      <td>cash_withdrawal_charge</td>\n",
              "      <td>cash_withdrawal_charge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Your machine took my card. How do I get it back?</td>\n",
              "      <td>card_swallowed</td>\n",
              "      <td>0</td>\n",
              "      <td>card_swallowed</td>\n",
              "      <td>card_swallowed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Why have I been charged an extra pound?</td>\n",
              "      <td>extra_charge_on_statement</td>\n",
              "      <td>0</td>\n",
              "      <td>extra_charge_on_statement</td>\n",
              "      <td>extra_charge_on_statement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>I would like to get both Mastercard and Visa c...</td>\n",
              "      <td>visa_or_mastercard</td>\n",
              "      <td>0</td>\n",
              "      <td>visa_or_mastercard</td>\n",
              "      <td>visa_or_mastercard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>I received my American Express in Apple Pay, i...</td>\n",
              "      <td>apple_pay_or_google_pay</td>\n",
              "      <td>0</td>\n",
              "      <td>apple_pay_or_google_pay</td>\n",
              "      <td>apple_pay_or_google_pay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>What happens when I am charged twice?</td>\n",
              "      <td>transaction_charged_twice</td>\n",
              "      <td>0</td>\n",
              "      <td>transaction_charged_twice</td>\n",
              "      <td>transaction_charged_twice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Can I use American express with apple pay? Why...</td>\n",
              "      <td>apple_pay_or_google_pay</td>\n",
              "      <td>0</td>\n",
              "      <td>apple_pay_or_google_pay</td>\n",
              "      <td>apple_pay_or_google_pay</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9b8f62a-a0ac-42b4-945b-74373210fdd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9b8f62a-a0ac-42b4-945b-74373210fdd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9b8f62a-a0ac-42b4-945b-74373210fdd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a728b9db-ebc9-48a3-acc6-0e80730e9c1f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a728b9db-ebc9-48a3-acc6-0e80730e9c1f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a728b9db-ebc9-48a3-acc6-0e80730e9c1f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_test_combined_df",
              "summary": "{\n  \"name\": \"train_test_combined_df\",\n  \"rows\": 10003,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10003,\n        \"samples\": [\n          \"i havent got my card\",\n          \"How long does it take for my payment to process?\",\n          \"Why am I being charged certain fees? I noticed a fee after I withdrew some money for groceries earlier today.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 77,\n        \"samples\": [\n          \"top_up_failed\",\n          \"card_not_working\",\n          \"activate_my_card\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"l\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 77,\n        \"samples\": [\n          \"top_up_failed\",\n          \"card_not_working\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"l_prime\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 77,\n        \"samples\": [\n          \"top_up_failed\",\n          \"card_not_working\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Create a DataFrame from the train_text and train_labels\n",
        "df_train = pd.DataFrame({\n",
        "    'text': train_text,\n",
        "    'category': full_noised_train_labels,\n",
        "    'k': 0,\n",
        "    'l': train_labels,\n",
        "    'l_prime': full_noised_train_labels\n",
        "})\n",
        "\n",
        "# Mark the noised samples in the 'k' column\n",
        "df_train.loc[train_noise_indices, 'k'] = 1\n",
        "\n",
        "# Repeat the same process for the test set\n",
        "df_test = pd.DataFrame({\n",
        "    'text': test_text,\n",
        "    'category': full_noised_test_labels,\n",
        "    'k': 0,\n",
        "    'l': test_labels,\n",
        "    'l_prime': full_noised_test_labels\n",
        "})\n",
        "\n",
        "df_test.loc[test_noise_indices, 'k'] = 1\n",
        "\n",
        "# Combine the train and test DataFrames\n",
        "train_test_combined_df = pd.concat([df_train, df_test])\n",
        "\n",
        "# Display the DataFrame to verify the changes\n",
        "train_test_combined_df.head(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4lURLlfpvNH"
      },
      "source": [
        "## Step 1: Define and Train Deep Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "u_SqANhepvNH"
      },
      "outputs": [],
      "source": [
        "device_name = 'cuda'\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
        "\n",
        "# Tokenize input text\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the training text\n",
        "train_input_text = np.array(train_text)\n",
        "train_input_ids = tokenizer.batch_encode_plus(train_input_text, padding=True, truncation=True, return_tensors='pt')['input_ids']\n",
        "train_attention_mask = tokenizer.batch_encode_plus(train_input_text, padding=True, truncation=True, return_tensors='pt')['attention_mask']\n",
        "\n",
        "# Tokenize and encode the testing text\n",
        "test_input_text = np.array(test_text)\n",
        "test_input_ids = tokenizer.batch_encode_plus(test_input_text, padding=True, truncation=True, return_tensors='pt')['input_ids']\n",
        "test_attention_mask = tokenizer.batch_encode_plus(test_input_text, padding=True, truncation=True, return_tensors='pt')['attention_mask']\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(full_noised_train_labels)\n",
        "test_labels_encoded = label_encoder.transform(full_noised_test_labels)  # Use transform for test labels\n",
        "\n",
        "# Convert encoded labels to tensors\n",
        "train_labels = torch.tensor(train_labels_encoded)\n",
        "test_labels = torch.tensor(test_labels_encoded)\n",
        "\n",
        "# Get the indices of the noised data\n",
        "noise_indices = test_noise_indices\n",
        "\n",
        "# Convert the indices to a tensor\n",
        "noise_indices = torch.tensor(noise_indices)\n",
        "\n",
        "# Create boolean masks for the noised and non-noised data\n",
        "mask_noised = torch.zeros(test_labels.size(0), dtype=torch.bool)\n",
        "mask_noised[noise_indices] = True\n",
        "mask_non_noised = ~mask_noised\n",
        "\n",
        "# Create TensorDatasets for the noised and non-noised parts of the test set\n",
        "test_dataset_noised = TensorDataset(test_input_ids[mask_noised], test_attention_mask[mask_noised], test_labels[mask_noised])\n",
        "test_dataset_non_noised = TensorDataset(test_input_ids[mask_non_noised], test_attention_mask[mask_non_noised], test_labels[mask_non_noised])\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_mask, train_labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "9EpSXuCSNFzs"
      },
      "outputs": [],
      "source": [
        "# from safetensors.torch import load_file\n",
        "# from transformers import BertModel\n",
        "# file_path = \"/content/drive/MyDrive/Zeta Test/model.safetensors\"\n",
        "# loaded = load_file(file_path)\n",
        "\n",
        "# model = BertModel.from_pretrained(loaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "R4XbuKoJYz89"
      },
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device_name), attention_mask.to(device_name), labels.to(device_name)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = criterion(outputs.logits, labels)  # Calculate cross-entropy loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            logits = outputs.logits\n",
        "            probs = torch.softmax(logits, dim=1)  # Calculate probabilities from logits\n",
        "            preds = torch.argmax(probs, dim=1)  # Get predictions from probabilities\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return total_loss / len(dataloader), all_preds, all_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Model Training and Evaluation for Text Classification with PyTorch"
      ],
      "metadata": {
        "id": "Rxuikxi97Rod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        out, _ = self.lstm(embedded)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = len(tokenizer.get_vocab())\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "label_encoder = LabelEncoder()\n",
        "num_classes = len(label_encoder.fit(full_noised_train_labels).classes_)\n",
        "\n",
        "# Initialize the LSTM model\n",
        "lstm_model = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device_name)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
        "\n",
        "# Create DataLoader for training and testing\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Training the LSTM model\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    lstm_model.train()\n",
        "    total_loss = 0.0\n",
        "    for inputs, masks, labels in train_loader:\n",
        "        inputs, masks, labels = inputs.to(device_name), masks.to(device_name), labels.to(device_name)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = lstm_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "# Evaluation on the test set\n",
        "lstm_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for inputs, masks, labels in test_loader:\n",
        "        inputs, masks, labels = inputs.to(device_name), masks.to(device_name), labels.to(device_name)\n",
        "        outputs = lstm_model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "print(f\"Test Accuracy: {accuracy}, F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKNBqj5My-HB",
        "outputId": "ab4935db-4630-42e1-e4e0-afdef64f7592"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 4.330410556706119\n",
            "Epoch 2/5, Loss: 4.320622322221869\n",
            "Epoch 3/5, Loss: 4.319946746303611\n",
            "Epoch 4/5, Loss: 4.3187909344015605\n",
            "Epoch 5/5, Loss: 4.317195134620144\n",
            "Test Accuracy: 0.01866044651782739, F1 Score: 0.0004759638267491671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model Performance on Different Data Subsets"
      ],
      "metadata": {
        "id": "UfYhU2jZ39xH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Define a function to evaluate model performance on a given subset of the test set\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, masks, labels in dataloader:\n",
        "            inputs, masks, labels = inputs.to(device_name), masks.to(device_name), labels.to(device_name)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    return accuracy, f1\n",
        "\n",
        "# Evaluate the LSTM model on different subsets of the test set\n",
        "# 1. Entire test set\n",
        "accuracy_entire_test, f1_entire_test = evaluate_model(lstm_model, test_loader)\n",
        "\n",
        "# 2. Noised part of the test set\n",
        "noised_test_loader = DataLoader(test_dataset_noised, batch_size=batch_size)\n",
        "accuracy_noised_test, f1_noised_test = evaluate_model(lstm_model, noised_test_loader)\n",
        "\n",
        "# 3. Non-noised part of the test set\n",
        "non_noised_test_loader = DataLoader(test_dataset_non_noised, batch_size=batch_size)\n",
        "accuracy_non_noised_test, f1_non_noised_test = evaluate_model(lstm_model, non_noised_test_loader)\n",
        "\n",
        "# Print evaluation metrics for each subset\n",
        "print(\"Performance on Entire Test Set:\")\n",
        "print(f\"Accuracy: {accuracy_entire_test}, F1 Score: {f1_entire_test}\")\n",
        "print(\"Performance on Noised Part of Test Set:\")\n",
        "print(f\"Accuracy: {accuracy_noised_test}, F1 Score: {f1_noised_test}\")\n",
        "print(\"Performance on Non-noised Part of Test Set:\")\n",
        "print(f\"Accuracy: {accuracy_non_noised_test}, F1 Score: {f1_non_noised_test}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_JkBG_H34DN",
        "outputId": "10fea982-1574-4276-aeae-eefa9225ee37"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance on Entire Test Set:\n",
            "Accuracy: 0.01866044651782739, F1 Score: 0.0004759638267491671\n",
            "Performance on Noised Part of Test Set:\n",
            "Accuracy: 0.012987012987012988, F1 Score: 0.000523286237571952\n",
            "Performance on Non-noised Part of Test Set:\n",
            "Accuracy: 0.01880984952120383, F1 Score: 0.00047970833733090287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Batch Size"
      ],
      "metadata": {
        "id": "GPQPHMQb4f5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 16\n",
        "\n",
        "# Assuming you have defined your LSTM model and DataLoader train_loader\n",
        "# Create DataLoader for training data with specified batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move model to the appropriate device\n",
        "model.to(device)\n",
        "\n",
        "# Modify the training loop to handle SequenceClassifierOutput\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, masks, labels = data\n",
        "        inputs, masks, labels = inputs.to(device), masks.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        logits = outputs.logits  # Extract logits from SequenceClassifierOutput\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:    # Print every 100 mini-batches\n",
        "            print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apyaQimc41uo",
        "outputId": "8d244933-3587-46fb-f092-7380c6a48058"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 4.380464692115783\n",
            "Epoch 1, Batch 200, Loss: 4.362850432395935\n",
            "Epoch 1, Batch 300, Loss: 4.3615529298782345\n",
            "Epoch 1, Batch 400, Loss: 4.353832459449768\n",
            "Epoch 2, Batch 100, Loss: 4.345209832191467\n",
            "Epoch 2, Batch 200, Loss: 4.348524522781372\n",
            "Epoch 2, Batch 300, Loss: 4.346203355789185\n",
            "Epoch 2, Batch 400, Loss: 4.358211913108826\n",
            "Epoch 3, Batch 100, Loss: 4.341966633796692\n",
            "Epoch 3, Batch 200, Loss: 4.33227958202362\n",
            "Epoch 3, Batch 300, Loss: 4.349987154006958\n",
            "Epoch 3, Batch 400, Loss: 4.349074077606201\n",
            "Epoch 4, Batch 100, Loss: 4.3483943319320675\n",
            "Epoch 4, Batch 200, Loss: 4.3441070938110355\n",
            "Epoch 4, Batch 300, Loss: 4.332904725074768\n",
            "Epoch 4, Batch 400, Loss: 4.330227727890015\n",
            "Epoch 5, Batch 100, Loss: 4.344835395812988\n",
            "Epoch 5, Batch 200, Loss: 4.331434617042541\n",
            "Epoch 5, Batch 300, Loss: 4.333095369338989\n",
            "Epoch 5, Batch 400, Loss: 4.345867395401001\n",
            "Epoch 6, Batch 100, Loss: 4.338492779731751\n",
            "Epoch 6, Batch 200, Loss: 4.333756799697876\n",
            "Epoch 6, Batch 300, Loss: 4.336419267654419\n",
            "Epoch 6, Batch 400, Loss: 4.331082768440247\n",
            "Epoch 7, Batch 100, Loss: 4.327102165222168\n",
            "Epoch 7, Batch 200, Loss: 4.3371470212936405\n",
            "Epoch 7, Batch 300, Loss: 4.3368068075180055\n",
            "Epoch 7, Batch 400, Loss: 4.342262434959411\n",
            "Epoch 8, Batch 100, Loss: 4.337854294776917\n",
            "Epoch 8, Batch 200, Loss: 4.3355907487869265\n",
            "Epoch 8, Batch 300, Loss: 4.3198001050949095\n",
            "Epoch 8, Batch 400, Loss: 4.333949060440063\n",
            "Epoch 9, Batch 100, Loss: 4.33242443561554\n",
            "Epoch 9, Batch 200, Loss: 4.329497404098511\n",
            "Epoch 9, Batch 300, Loss: 4.340881695747376\n",
            "Epoch 9, Batch 400, Loss: 4.337666144371033\n",
            "Epoch 10, Batch 100, Loss: 4.33861937046051\n",
            "Epoch 10, Batch 200, Loss: 4.335039558410645\n",
            "Epoch 10, Batch 300, Loss: 4.3257965040206905\n",
            "Epoch 10, Batch 400, Loss: 4.331339359283447\n",
            "Epoch 11, Batch 100, Loss: 4.3299939250946045\n",
            "Epoch 11, Batch 200, Loss: 4.33582389831543\n",
            "Epoch 11, Batch 300, Loss: 4.331347808837891\n",
            "Epoch 11, Batch 400, Loss: 4.341199984550476\n",
            "Epoch 12, Batch 100, Loss: 4.3325345420837404\n",
            "Epoch 12, Batch 200, Loss: 4.3312420082092284\n",
            "Epoch 12, Batch 300, Loss: 4.334375262260437\n",
            "Epoch 12, Batch 400, Loss: 4.319835543632507\n",
            "Epoch 13, Batch 100, Loss: 4.325779824256897\n",
            "Epoch 13, Batch 200, Loss: 4.32970269203186\n",
            "Epoch 13, Batch 300, Loss: 4.330770788192749\n",
            "Epoch 13, Batch 400, Loss: 4.338064866065979\n",
            "Epoch 14, Batch 100, Loss: 4.325255584716797\n",
            "Epoch 14, Batch 200, Loss: 4.328783311843872\n",
            "Epoch 14, Batch 300, Loss: 4.336364107131958\n",
            "Epoch 14, Batch 400, Loss: 4.3361801385879515\n",
            "Epoch 15, Batch 100, Loss: 4.320743732452392\n",
            "Epoch 15, Batch 200, Loss: 4.329940190315247\n",
            "Epoch 15, Batch 300, Loss: 4.343336272239685\n",
            "Epoch 15, Batch 400, Loss: 4.329337220191956\n",
            "Epoch 16, Batch 100, Loss: 4.332499918937683\n",
            "Epoch 16, Batch 200, Loss: 4.330823078155517\n",
            "Epoch 16, Batch 300, Loss: 4.328934760093689\n",
            "Epoch 16, Batch 400, Loss: 4.3317750501632695\n",
            "Epoch 17, Batch 100, Loss: 4.3290106344223025\n",
            "Epoch 17, Batch 200, Loss: 4.3405918741226195\n",
            "Epoch 17, Batch 300, Loss: 4.324988780021667\n",
            "Epoch 17, Batch 400, Loss: 4.319191799163819\n",
            "Epoch 18, Batch 100, Loss: 4.337299799919128\n",
            "Epoch 18, Batch 200, Loss: 4.33138421535492\n",
            "Epoch 18, Batch 300, Loss: 4.319989633560181\n",
            "Epoch 18, Batch 400, Loss: 4.3375721311569215\n",
            "Epoch 19, Batch 100, Loss: 4.320681123733521\n",
            "Epoch 19, Batch 200, Loss: 4.32749568939209\n",
            "Epoch 19, Batch 300, Loss: 4.328026251792908\n",
            "Epoch 19, Batch 400, Loss: 4.333753309249878\n",
            "Epoch 20, Batch 100, Loss: 4.329374413490296\n",
            "Epoch 20, Batch 200, Loss: 4.3229681634902954\n",
            "Epoch 20, Batch 300, Loss: 4.333661079406738\n",
            "Epoch 20, Batch 400, Loss: 4.333407211303711\n",
            "Epoch 21, Batch 100, Loss: 4.326657800674439\n",
            "Epoch 21, Batch 200, Loss: 4.328991928100586\n",
            "Epoch 21, Batch 300, Loss: 4.3270713901519775\n",
            "Epoch 21, Batch 400, Loss: 4.327535858154297\n",
            "Epoch 22, Batch 100, Loss: 4.332093744277954\n",
            "Epoch 22, Batch 200, Loss: 4.325647611618042\n",
            "Epoch 22, Batch 300, Loss: 4.337512874603272\n",
            "Epoch 22, Batch 400, Loss: 4.324870076179504\n",
            "Epoch 23, Batch 100, Loss: 4.326930088996887\n",
            "Epoch 23, Batch 200, Loss: 4.331004047393799\n",
            "Epoch 23, Batch 300, Loss: 4.332561836242676\n",
            "Epoch 23, Batch 400, Loss: 4.319276328086853\n",
            "Epoch 24, Batch 100, Loss: 4.3231749963760375\n",
            "Epoch 24, Batch 200, Loss: 4.340607886314392\n",
            "Epoch 24, Batch 300, Loss: 4.326694655418396\n",
            "Epoch 24, Batch 400, Loss: 4.326447138786316\n",
            "Epoch 25, Batch 100, Loss: 4.318492436408997\n",
            "Epoch 25, Batch 200, Loss: 4.325177884101867\n",
            "Epoch 25, Batch 300, Loss: 4.3296121311187745\n",
            "Epoch 25, Batch 400, Loss: 4.331356258392334\n",
            "Epoch 26, Batch 100, Loss: 4.338015928268432\n",
            "Epoch 26, Batch 200, Loss: 4.325975213050842\n",
            "Epoch 26, Batch 300, Loss: 4.329534111022949\n",
            "Epoch 26, Batch 400, Loss: 4.324794263839721\n",
            "Epoch 27, Batch 100, Loss: 4.315947771072388\n",
            "Epoch 27, Batch 200, Loss: 4.338223767280579\n",
            "Epoch 27, Batch 300, Loss: 4.331725339889527\n",
            "Epoch 27, Batch 400, Loss: 4.317729320526123\n",
            "Epoch 28, Batch 100, Loss: 4.334789552688599\n",
            "Epoch 28, Batch 200, Loss: 4.327315254211426\n",
            "Epoch 28, Batch 300, Loss: 4.330354199409485\n",
            "Epoch 28, Batch 400, Loss: 4.327921075820923\n",
            "Epoch 29, Batch 100, Loss: 4.312715454101562\n",
            "Epoch 29, Batch 200, Loss: 4.333422112464905\n",
            "Epoch 29, Batch 300, Loss: 4.321256265640259\n",
            "Epoch 29, Batch 400, Loss: 4.338823618888855\n",
            "Epoch 30, Batch 100, Loss: 4.3148449468612675\n",
            "Epoch 30, Batch 200, Loss: 4.327539172172546\n",
            "Epoch 30, Batch 300, Loss: 4.331830816268921\n",
            "Epoch 30, Batch 400, Loss: 4.330276513099671\n",
            "Finished Training\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}